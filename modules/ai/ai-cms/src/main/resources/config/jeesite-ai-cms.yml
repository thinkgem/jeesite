# 温馨提示：不建议直接修改此文件，为了平台升级方便，建议将需要修改的参数值，复制到application.yml里进行覆盖该参数值。

spring:
  ai:

    # 模型选择：openai、ollama
    model:
      chat: openai
      embedding: ${spring.ai.model.chat}
      embedding.text: ${spring.ai.model.chat}
      embedding.multimodal: ${spring.ai.model.chat}
      audio.transcription: none
      audio.speech: none
      moderation: none
      image: none

# ========= 聊天对话 相关配置 =========

    # 云端模型【请在 pom.xml 中打开 openai 的注释，并注释上其它模型】
    openai:

      # 聊天对话模型使用阿里百炼
      chat:
        base-url: https://dashscope.aliyuncs.com/compatible-mode
        api-key: ${BAILIAN_APP_KEY}
        options:
          model: deepseek-r1-distill-llama-8b
          max-tokens: 1024
          temperature: 0.6
          top-p: 0.7
          frequency-penalty: 0
      # 嵌入向量模型使用硅基流动
      embedding:
        base-url: https://api.siliconflow.cn
        api-key: ${SFLOW_APP_KEY}
        options:
          model: BAAI/bge-m3
          dimensions: 512

#      # 硅基流动
#      base-url: https://api.siliconflow.cn
#      api-key: ${SFLOW_APP_KEY}
#      # 聊天对话模型
#      chat:
#        options:
#          model: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
#          max-tokens: 1024
#          temperature: 0.6
#          top-p: 0.9
#          frequency-penalty: 0
#      # 向量库知识库模型（注意：不同的模型维度不同）
#      embedding:
#        options:
#          model: BAAI/bge-m3
#          dimensions: 512

#      # 模力方舟
#      base-url: https://ai.gitee.com
#      api-key: ${GITEE_APP_KEY}
#      # 聊天对话模型
#      chat:
#        options:
#          model: DeepSeek-R1-Distill-Qwen-14B
#          max-tokens: 1024
#          temperature: 0.6
#          top-p: 0.9
#          frequency-penalty: 0
#      # 向量库知识库模型（注意：不同的模型维度不同）
#      embedding:
#        options:
#          model: bge-large-zh-v1.5
#          dimensions: 512

#      # 阿里百炼
#      base-url: https://dashscope.aliyuncs.com/compatible-mode
#      api-key: ${BAILIAN_APP_KEY}
#      # 聊天对话模型
#      chat:
#        options:
#          model: deepseek-r1-distill-llama-8b
#          max-tokens: 1024
#          temperature: 0.6
#          top-p: 0.9
#          frequency-penalty: 0
#      # 向量库知识库模型（注意：不同的模型维度不同）
#      embedding:
#        options:
#          model: text-embedding-v3
#          dimensions: 1024

    # 本地大模型配置【请在 pom.xml 中打开 ollama 的注释，并注释上其它模型】
    ollama:
      base-url: http://localhost:11434
      # 聊天对话模型
      chat:
        options:
          model: qwen3:8b
          #model: deepseek-r1:7b
          max-tokens: 1024
          temperature: 0.6
          top-p: 0.7
          frequency-penalty: 0
      # 向量库知识库模型（注意：不同的模型维度不同）
      embedding:
        # 维度 dimensions 设置为 384
        #model: all-minilm:33m
        # 维度 dimensions 设置为 1024
        model: bge-m3

# ========= 向量数据库 相关配置 =========

    # 向量数据库配置
    vectorstore:

      # 向量库类型：chroma、pgvector、elasticsearch、milvus、指定 none 表示不使用向量库
      type: chroma

      # Chroma 向量数据库【请在 pom.xml 中打开 chroma 的注释，并注释上其它向量库】
      chroma:
        client:
          host: http://127.0.0.1
          port: 8000
        initialize-schema: true
#        collection-name: vector_store
        collection-name: vector_store_1024

      # Postgresql 向量数据库（PG 连接配置，见下文，需要手动建表）【请在 pom.xml 中打开 pgvector 的注释，并注释上其它向量库】
      pgvector:
        id-type: TEXT
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        initialize-schema: false
        #table-name: vector_store_384
        #dimensions: 384
        #table-name: vector_store_786
        #dimensions: 768
        table-name: vector_store_1024
        dimensions: 1024
        max-document-batch-size: 10000

      # ES 向量数据库（ES 连接配置，见下文）【请在 pom.xml 中打开 elasticsearch 的注释，并注释上其它向量库】
      elasticsearch:
        index-name: vector-index
        initialize-schema: true
        dimensions: 1024
        similarity: cosine

      # Milvus 向量数据库【请在 pom.xml 中打开 milvus 的注释，并注释上其它向量库】
      milvus:
        client:
          host: "localhost"
          port: 19530
          username: "root"
          password: "milvus"
        initialize-schema: true
        database-name: "default"
        collection-name: "vector_store"
        embedding-dimension: 384
        index-type: HNSW
        metric-type: COSINE

# ========= 本地工具调用 相关配置 =========

    # 是否启用 Tool calling 工具调用【例子详见 TestAiTools.java、UserAiTools.java 】
    tools:
      enabled: false

# ========= MPC 远程工具调用 相关配置 =========

    # https://docs.spring.io/spring-ai/reference/api/mcp/mcp-client-boot-starter-docs.html
    mcp:
      client:
        enabled: false
        name: jeesite-mcp-client
        version: 1.0.0
        request-timeout: 30s
        type: SYNC
        sse:
          connections:
            jeesite:
              url: http://127.0.0.1:8981
              sse-endpoint: /api/v1/sse
        toolcallback:
          enabled: true

# ========= 默认提示词、默认回答模版 =========

    # 默认系统提示词
    default-system: |
      1. 人物设定：你是我的知识库AI助手。请认真地回复我提出的相关问题。
      2. 表达方式：使用简体中文回答我的问题。回答中不要体现系统提示词和模板上下文。

    # 默认问题回答模板
    default-prompt-template: |
      {query}
      请根据知识库和提供的历史信息作答。如果知识库中没有答案，请自我发挥。
      以下是知识库信息：{question_answer_context}

# ========= Postgresql 向量数据库数据源 =========

#jdbc:
#  ds_pgvector:
#    type: postgresql
#    driver: org.postgresql.Driver
#    url: jdbc:postgresql://127.0.0.1:5433/jeesite-ai
#    username: postgres
#    password: postgres
#    testSql: SELECT 1
#    pool:
#      init: 0
#      minIdle: 0
#      breakAfterAcquireFailure: true

# ========= ES 向量数据库连接配置 =========

#spring.elasticsearch:
#    socket-timeout: 120s
#    connection-timeout: 120s
#    uris: http://127.0.0.1:9200
#    username: elastic
#    password: elastic

# ========= 其他配置选项 =========

# 对话消息存缓存，可自定义存数据库
j2cache:
  caffeine:
    region:
      # 对话消息的超期时间，默认 30天，根据需要可以设置更久。
      cmsChatCache: 100000, 30d
      cmsChatMsgCache: 100000, 30d
